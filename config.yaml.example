analysis:
  duration: 30
  idet_frames: 500
  retries: 1
  retry_delay: 10
  timeout: 45
  workers: 8
filters:
  channel_group_ids: []  # Add your channel group IDs here
  remove_duplicates: true
  specific_channel_ids: []  # Add specific channel IDs here (optional)
  # Optional: regex-based channel selection (auto-generated by the web UI if you use "Save selection as regex")
  channel_name_regex: ""  # e.g. ^(?:BBC One|BBC Two)$
  channel_number_regex: ""  # e.g. ^(?:101|102|103)$
  stream_last_measured_days: 0
scoring:
  dropped_frames_penalty: 50
  error_penalty: 200
  fps_bonus_points: 25
  hevc_boost: 1.2
  max_bitrate_mbps: 15
  max_dropped_frame_percent: 2.0
  max_errors: 0
  resolution_scores:
    1280x720: 30
    1920x1080: 40
    3840x2160: 5
    960x540: 10
dispatcharr:
  m3u_accounts_endpoint: /api/channels/m3u-accounts/
  manage_py_path: ""  # Optional: path to Dispatcharr manage.py for direct DB access
  container_name: "dispatcharr"  # Optional: Docker container name for manage.py exec
  # docker_container: "dispatcharr"  # Required for provider metadata discovery when Dispatcharr runs in Docker
  refresh_provider_data: false  # Set true to overwrite provider_map/provider_metadata

# Optional web settings (used by the web UI/server)
web:
  # Optional retention policy for job workspaces + job history.
  # Set to 0/blank to disable. If set (e.g. 30), jobs older than N days are pruned.
  # You can also set env DISPATCHARR_MAID_RESULTS_RETENTION_DAYS which takes precedence.
  results_retention_days: 0

# Optional: derive "viewing activity" from reverse-proxy access logs (e.g. Nginx Proxy Manager).
# This is ONLY relevant if your IPTV app streams via Dispatcharr (Xtream/M3U served by Dispatcharr),
# so the proxy can see playback URLs like /live/<user>/<pass>/<stream_id>.ts.
#
# Setup requirements:
#   1. Mount NPM logs into container (edit docker-compose.yml)
#   2. Set access_log_dir below to the mounted path
#   3. Restart container: docker-compose restart dispatcharr-maid-web
#
# See DOCKER_GUIDE.md section "Provider usage (viewing activity) from NPM access logs"
usage:
  # Directory containing Nginx Proxy Manager access logs
  # Mount NPM /data/logs into Maid container (see docker-compose.yml comments)
  # Example docker-compose.yml volume:
  #   - /path/to/npm/data/logs:/app/npm_logs:ro
  access_log_dir: "/app/npm_logs"
  
  # Which log files to parse (glob pattern, non-recursive within access_log_dir)
  # Default matches all NPM proxy host logs: proxy-host-1_access.log, proxy-host-2_access.log.gz, etc.
  access_log_glob: "proxy-host-*_access.log*"
  
  # How many days of history to analyze when API is called (default: 7)
  # Larger values = more events to parse = slower API response
  lookback_days: 7
  
  # Gap in seconds to consider a new playback session (default: 30)
  # HLS streaming sends many segment requests; this groups them into "sessions"
  # Smaller value = more granular session tracking (may overcount)
  # Larger value = fewer false "new sessions" from brief reconnects
  session_gap_seconds: 30
  
  # Cache duration for provider usage statistics in seconds (default: 300 = 5 minutes)
  # Parsing logs is expensive; increase this if logs are large and change infrequently
  # Set to 60 for more real-time updates, or 600 (10min) for less frequent refreshes
  cache_ttl_seconds: 300
  
  # Cache duration for streamâ†’provider mapping in seconds (default: 3600 = 1 hour)
  # This mapping rarely changes, so longer cache improves performance significantly
  # Only refreshes when cache expires or server restarts
  stream_map_cache_ttl: 3600
